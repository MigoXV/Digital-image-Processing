# 3.2 Huffman 编码（熵编码）

图象熵：
图像灰度集合为 $\left(x_1, x_2, \ldots, x_{M}\right)$, , 对应的概率 $P_1$, $P_2, \ldots, \mathbf{P}_{M}$
则图象熵: $\quad H=-\sum_{k=1}^M P_k \log P_k$
平均码长:
设 $\beta_{k}$ 为图像第 $k$ 个码长 $C_{k}$ 的长度, 对应的概率为 $P_{k}$, 则该 图象所赋予的码长的平均长度为:
$$
R=\sum_{k=1}^M \beta_k P_k
$$
编码效率
$$
\eta=\frac{H}{R}
$$
变长最佳编码定理
在变长编码中, 对图像中出现频度大的像素值赋 予短码字, 对出现频度小的像数值赋予长码字。 如果严格按照所对应符号出现概率大小逆序排列, 则编码结果平均码长一定小于任何其它排列方式。
Huffman 编码
根据变长最佳编码定理, 应用Huffman算法的一种 编码方法。

举例：
$$
\frac{\text { aaaa }}{4} \frac{bbb}{3} \frac{cc}{2} \frac{d}{1} \frac{\text { eeeee }}{5} \frac{\text { fffffff }}{7} \text { (共22*8=176 bits) }
$$
编码: $f=0 \quad e=10 \quad a=110 \quad ~b=1111 \quad c=11100 \quad ~d=11101$

11011011011011111111111111100111001110110101010100000000
(共 $7 * 1+5 * 2+4 * 3+3 * 4+2 * 5+1 * 5=56$ bits)

Huffman 编码步骤:
1、先将图象灰度级按出现的概率由大到小顺序排列;
2、将最小两个概率相加, 形成一个新的概率集合, 再按第 (1) 步方法重排, 如此重复进行直到只有 两个概率为止;
3、分配码长。码长分配从最后一步开始反向进行, 对最后两个概率一个赋予“0”, 一个赋予“1”

![image-20230419195748059](https://mypic-1312707183.cos.ap-nanjing.myqcloud.com/image-20230419195748059.png)

整理:

![image-20230419195814242](https://mypic-1312707183.cos.ap-nanjing.myqcloud.com/image-20230419195814242.png)

f=01   e=11   a=10   b=001    c=0001   d=0000
$$
\frac{\text { aaaa }}{4} \frac{bbb}{3} \frac{cc}{2} \frac{d}{1} \frac{\text { eeeee }}{5} \frac{\text { fffffff }}{7} \text { (共22*8=176 bits) }
$$
经过Huffman编码之后的数据为：

1010101010001001001000100010000111111111101010101010101

(共 $7 * 2+5 * 2+4 * 2+3 * 3+2 * 4+1 * 4=53$ bits)
比前面我们给出的编码得到的56bits的数据量还小

Huffman编码在图像压缩中的实现
我们知道, 对一幅图像进行编码时, 如果图 像的大小大于 256 时, 这幅图像的不同的码字就 有可能是很大, 例如极限为 256 个不同的码字。
对整幅图直接进行Huffman编码时, 小分布 的灰度值, 就有可能具有很长的编码。
如: 100位以上, 这样不但达不到压缩的效 果反而会使数据量加大, 应该如何处理?

常用的且有效的方法是:
将图像分割成若干的小块, 对每块进行 独立的Huffman编码。例如: 分成$8\times 8$的子块, 就可以大大降低不同灰度值的个数（最多是64而不是256）。